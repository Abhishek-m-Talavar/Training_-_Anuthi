{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e28e875b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac009f7b",
   "metadata": {},
   "source": [
    "# sigmoid Perceptron Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "00822406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SigmoidPerceptron():\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "    \n",
    "    def fit(self, inputs, targets, learning_rate, num_epochs):\n",
    "        num_examples = inputs.shape[0]\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(num_examples):\n",
    "                input_vector = inputs[i]\n",
    "                target = targets[i]\n",
    "                prediction = self.predict(input_vector)\n",
    "                error = target - prediction\n",
    "                \n",
    "#                 update weigts\n",
    "                gradient_weights = error * prediction * (1-prediction) * input_vector\n",
    "                self.weights += learning_rate * gradient_weights\n",
    "        \n",
    "#                 uPDATE BIAS\n",
    "                gradient_bias = error * prediction * (1-prediction)\n",
    "                self.bias += learning_rate * gradient_bias\n",
    "        \n",
    "    def evaluate(self, inputs, targets):\n",
    "        correct = 0\n",
    "        for input_vector, target in zip(inputs, targets):\n",
    "            prediction = self.predict(input_vector)\n",
    "            predicted_class = 1 if prediction >= 0.5 else 0\n",
    "            \n",
    "            if predicted_class == target:\n",
    "                correct +=1\n",
    "        accuracy = correct / len(inputs)   #accuracy no. of correct prediction / total number of data points\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1fe162e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "[1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0\n",
      " 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1\n",
      " 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1] [[ 2.30224209e-01 -2.77326414e-02  2.27975215e-01 ...  2.00842634e-01\n",
      "  -7.57120514e-01  3.34027585e-01]\n",
      " [ 1.37933163e+00  1.37043732e+00  2.04423277e+00 ...  1.58632458e+00\n",
      "   6.58810669e-01  1.69965200e+00]\n",
      " [-6.31606358e-01 -8.90433256e-01 -7.81056760e-01 ... -7.59272048e-01\n",
      "   7.35118338e-01 -1.03159683e+00]\n",
      " ...\n",
      " [ 2.30224209e-01 -3.84712206e-01 -1.75637575e-01 ...  6.62669949e-01\n",
      "  -6.41245906e-01  5.90082163e-01]\n",
      " [-1.20616007e+00  2.01565564e-03 -7.47343776e-02 ... -9.29418953e-01\n",
      "  -7.96687453e-01 -1.11694836e+00]\n",
      " [ 1.37933163e+00  1.50757141e-01  2.61688199e-02 ...  2.25149335e-01\n",
      "   4.63802183e-01  9.31488268e-01]]\n",
      "Training Accuracy = 76.87 %\n",
      "Testing Accuracy = 75.0 %\n"
     ]
    }
   ],
   "source": [
    "# 📦 Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 📥 Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 🧪 Check class distribution\n",
    "print(df['Outcome'].value_counts())\n",
    "\n",
    "# ⚖️ Balance the dataset by undersampling class 0\n",
    "class_0_df = df[df['Outcome'] == 0].sample(268, random_state=42)  # same as class 1 count\n",
    "class_1_df = df[df['Outcome'] == 1]\n",
    "data = pd.concat([class_0_df, class_1_df])\n",
    "\n",
    "# 🧹 Shuffle the combined dataset\n",
    "# data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 🧾 Separate features and labels\n",
    "X = data.drop('Outcome', axis=1).values  # Convert to NumPy array\n",
    "Y = data['Outcome'].values               # Convert to NumPy array\n",
    "\n",
    "# 🧪 Split into training and testing sets (stratified to preserve class balance)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=Y, random_state=42\n",
    ")\n",
    "\n",
    "# 🔍 Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)  # use transform, not fit_transform\n",
    "\n",
    "# 🧠 Define the Sigmoid Perceptron class\n",
    "class SigmoidPerceptron():\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()  # scalar bias\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "    \n",
    "    def fit(self, inputs, targets, learning_rate, num_epochs):\n",
    "        targets = targets.flatten()  # ensure 1D\n",
    "        print(targets, inputs)\n",
    "        for epoch in range(num_epochs):\n",
    "            for input_vector, target in zip(inputs, targets):\n",
    "                prediction = self.predict(input_vector)\n",
    "                error = target - prediction\n",
    "\n",
    "                # Gradient descent update\n",
    "                gradient_weights = error * prediction * (1 - prediction) * input_vector\n",
    "                self.weights += learning_rate * gradient_weights\n",
    "\n",
    "                gradient_bias = error * prediction * (1 - prediction)\n",
    "                self.bias += learning_rate * gradient_bias\n",
    "    \n",
    "    def evaluate(self, inputs, targets):\n",
    "        correct = 0\n",
    "        for input_vector, target in zip(inputs, targets):\n",
    "            prediction = self.predict(input_vector)\n",
    "            predicted_class = 1 if prediction >= 0.5 else 0\n",
    "            if predicted_class == target:\n",
    "                correct += 1\n",
    "        accuracy = correct / len(inputs)\n",
    "        return accuracy\n",
    "\n",
    "# 🏋️‍♂️ Initialize and train the model\n",
    "perceptron = SigmoidPerceptron(input_size=X_train_scaler.shape[1])\n",
    "perceptron.fit(inputs=X_train_scaler, targets=Y_train, learning_rate=0.1, num_epochs=100)\n",
    "\n",
    "# 📊 Evaluate on training data\n",
    "train_accuracy = perceptron.evaluate(X_train_scaler, Y_train)\n",
    "print(\"Training Accuracy =\", round(train_accuracy * 100, 2), '%')\n",
    "\n",
    "# 📊 Evaluate on testing data\n",
    "test_accuracy = perceptron.evaluate(X_test_scaler, Y_test)\n",
    "print(\"Testing Accuracy =\", round(test_accuracy * 100, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fdf97ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 8)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b14e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62502c14",
   "metadata": {},
   "source": [
    "# sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22921cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3a684",
   "metadata": {},
   "source": [
    "# ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ad13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return x if x>0 else 0\n",
    "print(relu(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20299286",
   "metadata": {},
   "source": [
    "# tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e687f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
    "print(tanh(-23))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0a524",
   "metadata": {},
   "source": [
    "# Softmax Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2051aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.475217368561138\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exp_x= [math.exp(i) for i in x]\n",
    "    sum_exp_x = sum(exp_x)\n",
    "    return sum_exp_x\n",
    "print(softmax([2,1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98db69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96095eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec92ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae90cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abc619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f465c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d3a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e4260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e6905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7d264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285f5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d96ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed86d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f4a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145101e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42defeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bc04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc585e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d4ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeb048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df85c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37431bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80748f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c70b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12b6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59801794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cff1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c569d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8cea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294eba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13016c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63028c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09be22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f920dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c421e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c023d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36b1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533221c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef246a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93966bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a401d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de900c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd18f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682efc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd547799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
